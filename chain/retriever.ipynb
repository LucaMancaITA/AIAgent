{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cb963bc-e938-4cd6-907c-6cb79d60649d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucamanca/Codes/AIAgent/env/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"attention.pdf\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b558ba4d-83d4-48b1-8895-62e2adf3f4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
    "text_splitter.split_documents(docs)[:5]\n",
    "\n",
    "documents=text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3630e1f-4a98-4ad0-b736-230cf835d3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# Vector databse\n",
    "db = FAISS.from_documents(documents[:30], OllamaEmbeddings(model=\"all-minilm\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ba8719d-2e9d-4b17-ab59-e23a15f28861",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "\n",
    "# Load Ollama LAMA2 LLM model\n",
    "llm = Ollama(model=\"llama2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ce615a4-b460-4491-a003-d36c8fdfe73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Design ChatPrompt Template\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Answer the following question based only on the provided context. \n",
    "Think step by step before providing a detailed answer. \n",
    "I will tip you $1000 if the user finds the answer helpful. \n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "Question: {input}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d67231b-f017-4963-8ec1-5d65335f78f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "# Chain\n",
    "document_chain = create_stuff_documents_chain(\n",
    "    llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8fb0cbba-a644-4bdb-a7cf-7f99b22adf77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x1220a0820>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Retrievers: A retriever is an interface that returns documents given\n",
    " an unstructured query. It is more general than a vector store.\n",
    " A retriever does not need to be able to store documents, only to \n",
    " return (or retrieve) them. Vector stores can be used as the backbone\n",
    " of a retriever, but there are other types of retrievers as well. \n",
    " https://python.langchain.com/docs/modules/data_connection/retrievers/   \n",
    "\"\"\"\n",
    "\n",
    "# Retriever\n",
    "retriever = db.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f017d6a6-67bf-4591-a61b-ec805a804e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "\"\"\"\n",
    "Retrieval chain:This chain takes in a user inquiry, which is then\n",
    "passed to the retriever to fetch relevant documents. Those documents \n",
    "(and original inputs) are then passed to an LLM to generate a response\n",
    "https://python.langchain.com/docs/modules/chains/\n",
    "\"\"\"\n",
    "\n",
    "# Retriever chain\n",
    "retrieval_chain = create_retrieval_chain(\n",
    "    retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d2341ff-62ce-4c25-9d59-60f5eb431dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = retrieval_chain.invoke({\n",
    "    \"input\": \"Scaled Dot-Product Attention\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d88df0e-e6b6-48e7-9206-51af93f58a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The answer to the question \"Scaled Dot-Product Attention\" is based on the provided context.\\n\\nIn the context, the authors propose a type of attention mechanism called \"Scaled Dot-Product Attention.\" This attention mechanism is similar to the dot-product attention mechanism, but with a scaling factor of √dk. The scaling factor is introduced to counteract the effect of large dot products in the softmax function, which can result in small gradients.\\n\\nThe authors explain that for small values of dk, the two mechanisms perform similarly, but for larger values of dk, additive attention outperforms dot-product attention without scaling. They suspect that for large values of dk, the dot products grow large in magnitude, pushing the softmax function into regions where it has extremely small gradients. By introducing the scaling factor, they are able to stabilize the attention mechanism and improve its performance.\\n\\nIn summary, Scaled Dot-Product Attention is a type of attention mechanism that combines the benefits of dot-product attention with the stability of additive attention by introducing a scaling factor to the dot products.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4439ae5-fc13-4033-9f5a-01ba4a496e3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
